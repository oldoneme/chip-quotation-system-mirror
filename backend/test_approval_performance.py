#!/usr/bin/env python3
"""
ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿæ€§èƒ½æµ‹è¯•
æµ‹è¯•APIå“åº”æ—¶é—´å’Œå¹¶å‘æ€§èƒ½
"""

import sys
import os
import asyncio
import aiohttp
import time
import statistics
from datetime import datetime
import json

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# APIé…ç½®
BASE_URL = "http://127.0.0.1:8000"
API_V2_BASE = f"{BASE_URL}/api/v2/approval"

class PerformanceTest:
    """æ€§èƒ½æµ‹è¯•ç±»"""

    def __init__(self):
        self.session = None
        self.results = []

    async def setup_session(self):
        """è®¾ç½®HTTPä¼šè¯"""
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=50)
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(connector=connector, timeout=timeout)
        logger.info("HTTPä¼šè¯å·²å»ºç«‹")

    async def cleanup_session(self):
        """æ¸…ç†HTTPä¼šè¯"""
        if self.session:
            await self.session.close()
            logger.info("HTTPä¼šè¯å·²å…³é—­")

    async def test_api_response_time(self, endpoint: str, method: str = "GET", data: dict = None, repeat: int = 100):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        test_name = f"{method} {endpoint}"
        logger.info(f"å¼€å§‹æ€§èƒ½æµ‹è¯•: {test_name} (é‡å¤ {repeat} æ¬¡)")

        response_times = []
        success_count = 0
        error_count = 0

        for i in range(repeat):
            start_time = time.time()

            try:
                if method.upper() == "GET":
                    async with self.session.get(f"{API_V2_BASE}{endpoint}") as response:
                        await response.read()
                        if response.status == 200:
                            success_count += 1
                        else:
                            error_count += 1
                elif method.upper() == "POST":
                    async with self.session.post(
                        f"{API_V2_BASE}{endpoint}",
                        json=data,
                        headers={"Content-Type": "application/json"}
                    ) as response:
                        await response.read()
                        if response.status == 200:
                            success_count += 1
                        else:
                            error_count += 1

                end_time = time.time()
                response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                response_times.append(response_time)

            except Exception as e:
                error_count += 1
                logger.warning(f"è¯·æ±‚å¤±è´¥: {e}")

            # æ¯10æ¬¡è¾“å‡ºè¿›åº¦
            if (i + 1) % 10 == 0:
                logger.info(f"è¿›åº¦: {i + 1}/{repeat}")

        if response_times:
            avg_time = statistics.mean(response_times)
            min_time = min(response_times)
            max_time = max(response_times)
            p95_time = statistics.quantiles(response_times, n=20)[18]  # 95th percentile

            result = {
                'test_name': test_name,
                'total_requests': repeat,
                'success_count': success_count,
                'error_count': error_count,
                'avg_response_time': round(avg_time, 2),
                'min_response_time': round(min_time, 2),
                'max_response_time': round(max_time, 2),
                'p95_response_time': round(p95_time, 2),
                'success_rate': round((success_count / repeat) * 100, 2)
            }

            self.results.append(result)
            logger.info(f"âœ… {test_name} å®Œæˆ:")
            logger.info(f"   æˆåŠŸç‡: {result['success_rate']}%")
            logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']}ms")
            logger.info(f"   P95å“åº”æ—¶é—´: {result['p95_response_time']}ms")

        else:
            logger.error(f"âŒ {test_name} æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")

    async def test_concurrent_requests(self, endpoint: str, concurrent_users: int = 10, requests_per_user: int = 5):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        test_name = f"å¹¶å‘æµ‹è¯• {endpoint} ({concurrent_users}ç”¨æˆ· x {requests_per_user}è¯·æ±‚)"
        logger.info(f"å¼€å§‹å¹¶å‘æµ‹è¯•: {test_name}")

        async def user_requests():
            """å•ä¸ªç”¨æˆ·çš„è¯·æ±‚"""
            user_times = []
            for _ in range(requests_per_user):
                start_time = time.time()
                try:
                    async with self.session.get(f"{API_V2_BASE}{endpoint}") as response:
                        await response.read()
                        end_time = time.time()
                        response_time = (end_time - start_time) * 1000
                        user_times.append(response_time)
                except Exception as e:
                    logger.warning(f"å¹¶å‘è¯·æ±‚å¤±è´¥: {e}")
            return user_times

        # å¯åŠ¨å¹¶å‘ä»»åŠ¡
        start_time = time.time()
        tasks = [user_requests() for _ in range(concurrent_users)]
        all_results = await asyncio.gather(*tasks)
        end_time = time.time()

        # æ”¶é›†ç»“æœ
        all_times = []
        for user_times in all_results:
            all_times.extend(user_times)

        total_requests = concurrent_users * requests_per_user
        total_time = (end_time - start_time) * 1000

        if all_times:
            avg_time = statistics.mean(all_times)
            throughput = len(all_times) / (total_time / 1000)  # è¯·æ±‚/ç§’

            result = {
                'test_name': test_name,
                'concurrent_users': concurrent_users,
                'requests_per_user': requests_per_user,
                'total_requests': total_requests,
                'successful_requests': len(all_times),
                'total_time': round(total_time, 2),
                'avg_response_time': round(avg_time, 2),
                'throughput': round(throughput, 2),
                'success_rate': round((len(all_times) / total_requests) * 100, 2)
            }

            self.results.append(result)
            logger.info(f"âœ… {test_name} å®Œæˆ:")
            logger.info(f"   æˆåŠŸç‡: {result['success_rate']}%")
            logger.info(f"   ååé‡: {result['throughput']} è¯·æ±‚/ç§’")
            logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']}ms")

    async def run_performance_tests(self):
        """è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶"""
        logger.info("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•")

        # 1. APIå¥åº·æ£€æŸ¥æ€§èƒ½
        await self.test_api_response_time("/health", repeat=50)

        # 2. å®¡æ‰¹åˆ—è¡¨æŸ¥è¯¢æ€§èƒ½
        await self.test_api_response_time("/list?page=1&page_size=10", repeat=50)

        # 3. å¹¶å‘æµ‹è¯• - å¥åº·æ£€æŸ¥
        await self.test_concurrent_requests("/health", concurrent_users=10, requests_per_user=5)

        # 4. å¹¶å‘æµ‹è¯• - å®¡æ‰¹åˆ—è¡¨
        await self.test_concurrent_requests("/list?page=1&page_size=10", concurrent_users=5, requests_per_user=3)

        logger.info("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")

    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿæ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()

        for result in self.results:
            print(f"æµ‹è¯•é¡¹ç›®: {result['test_name']}")

            if 'concurrent_users' in result:
                # å¹¶å‘æµ‹è¯•ç»“æœ
                print(f"  å¹¶å‘ç”¨æˆ·æ•°: {result['concurrent_users']}")
                print(f"  æ¯ç”¨æˆ·è¯·æ±‚æ•°: {result['requests_per_user']}")
                print(f"  æ€»è¯·æ±‚æ•°: {result['total_requests']}")
                print(f"  æˆåŠŸè¯·æ±‚æ•°: {result['successful_requests']}")
                print(f"  æˆåŠŸç‡: {result['success_rate']}%")
                print(f"  æ€»è€—æ—¶: {result['total_time']}ms")
                print(f"  å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']}ms")
                print(f"  ååé‡: {result['throughput']} è¯·æ±‚/ç§’")
            else:
                # å“åº”æ—¶é—´æµ‹è¯•ç»“æœ
                print(f"  æ€»è¯·æ±‚æ•°: {result['total_requests']}")
                print(f"  æˆåŠŸæ•°: {result['success_count']}")
                print(f"  å¤±è´¥æ•°: {result['error_count']}")
                print(f"  æˆåŠŸç‡: {result['success_rate']}%")
                print(f"  å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']}ms")
                print(f"  æœ€å°å“åº”æ—¶é—´: {result['min_response_time']}ms")
                print(f"  æœ€å¤§å“åº”æ—¶é—´: {result['max_response_time']}ms")
                print(f"  P95å“åº”æ—¶é—´: {result['p95_response_time']}ms")

            print()

        # æ€§èƒ½è¯„ä¼°
        print("-" * 80)
        print("ğŸ¯ æ€§èƒ½è¯„ä¼°")
        print("-" * 80)

        avg_response_times = []
        success_rates = []

        for result in self.results:
            if 'avg_response_time' in result:
                avg_response_times.append(result['avg_response_time'])
                success_rates.append(result['success_rate'])

        if avg_response_times:
            overall_avg = statistics.mean(avg_response_times)
            overall_success = statistics.mean(success_rates)

            print(f"æ•´ä½“å¹³å‡å“åº”æ—¶é—´: {overall_avg:.2f}ms")
            print(f"æ•´ä½“æˆåŠŸç‡: {overall_success:.2f}%")

            # æ€§èƒ½è¯„çº§
            if overall_avg < 100 and overall_success > 99:
                print("ğŸ‰ æ€§èƒ½è¯„çº§: ä¼˜ç§€")
            elif overall_avg < 200 and overall_success > 95:
                print("âœ… æ€§èƒ½è¯„çº§: è‰¯å¥½")
            elif overall_avg < 500 and overall_success > 90:
                print("âš ï¸ æ€§èƒ½è¯„çº§: ä¸€èˆ¬")
            else:
                print("âŒ æ€§èƒ½è¯„çº§: éœ€è¦ä¼˜åŒ–")

async def main():
    """ä¸»å‡½æ•°"""
    test_runner = PerformanceTest()

    try:
        await test_runner.setup_session()
        await test_runner.run_performance_tests()
        test_runner.print_performance_report()

        return True

    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

    finally:
        await test_runner.cleanup_session()

if __name__ == "__main__":
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸ æ€§èƒ½æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
#!/usr/bin/env python3
"""
Step 6: ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿ - å…¨é¢ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
éªŒè¯ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç«¯åˆ°ç«¯æµ‹è¯•ã€APIæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•

æµ‹è¯•èŒƒå›´ï¼š
1. ç»Ÿä¸€å®¡æ‰¹APIç«¯ç‚¹å®Œæ•´æ€§æµ‹è¯•
2. æ•°æ®æµå’ŒçŠ¶æ€åŒæ­¥æµ‹è¯•
3. ä¼ä¸šå¾®ä¿¡/å†…éƒ¨å®¡æ‰¹å…¼å®¹æ€§æµ‹è¯•
4. å‰ç«¯ç»„ä»¶é›†æˆæµ‹è¯•
5. æ€§èƒ½å’Œè´Ÿè½½æµ‹è¯•
6. é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶æµ‹è¯•
"""

import os
import sys
import time
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import requests
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from app.database import SQLALCHEMY_DATABASE_URL


class UnifiedApprovalSystemTest:
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿæµ‹è¯•å™¨"""
        self.base_url = "http://127.0.0.1:8000"
        self.frontend_url = "http://localhost:3000"
        self.test_quote_id = "2a72d639-1486-442d-bce3-02a20672de28"

        # ç¦ç”¨ä»£ç†
        os.environ['http_proxy'] = ''
        os.environ['https_proxy'] = ''

        # æ•°æ®åº“è¿æ¥
        self.engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
        SessionLocal = sessionmaker(bind=self.engine)
        self.db = SessionLocal()

        # æµ‹è¯•ç»“æœè®°å½•
        self.test_results = {
            "test_session_id": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "start_time": datetime.now().isoformat(),
            "end_time": None,
            "duration": None,
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "warnings": 0,
            "test_categories": {
                "api_endpoints": {"passed": 0, "failed": 0, "tests": []},
                "data_flow": {"passed": 0, "failed": 0, "tests": []},
                "integration": {"passed": 0, "failed": 0, "tests": []},
                "performance": {"passed": 0, "failed": 0, "tests": []},
                "error_handling": {"passed": 0, "failed": 0, "tests": []},
                "documentation": {"passed": 0, "failed": 0, "tests": []}
            },
            "system_info": {
                "test_quote_id": self.test_quote_id,
                "backend_url": self.base_url,
                "frontend_url": self.frontend_url
            },
            "recommendations": []
        }

    def log_test_result(self, category: str, test_name: str, status: str,
                       details: Dict = None, duration: float = None):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        result = {
            "name": test_name,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "duration": duration,
            "details": details or {}
        }

        self.test_results["test_categories"][category]["tests"].append(result)

        if status == "PASS":
            self.test_results["test_categories"][category]["passed"] += 1
            self.test_results["passed_tests"] += 1
        elif status == "FAIL":
            self.test_results["test_categories"][category]["failed"] += 1
            self.test_results["failed_tests"] += 1
        elif status == "WARN":
            self.test_results["warnings"] += 1

        self.test_results["total_tests"] += 1

    def test_api_endpoints_completeness(self):
        """æµ‹è¯•ç»Ÿä¸€å®¡æ‰¹APIç«¯ç‚¹å®Œæ•´æ€§"""
        print("ğŸ”§ æµ‹è¯•1: ç»Ÿä¸€å®¡æ‰¹APIç«¯ç‚¹å®Œæ•´æ€§")

        # é¢„æœŸçš„APIç«¯ç‚¹
        expected_endpoints = [
            "/api/v1/approval/status/{quote_id}",
            "/api/v1/approval/history/{quote_id}",
            "/api/v1/approval/submit/{quote_id}",
            "/api/v1/approval/approve/{quote_id}",
            "/api/v1/approval/reject/{quote_id}"
        ]

        for endpoint_pattern in expected_endpoints:
            endpoint = endpoint_pattern.format(quote_id=self.test_quote_id)
            test_name = f"APIç«¯ç‚¹å­˜åœ¨æ€§: {endpoint_pattern}"

            start_time = time.time()
            try:
                if "status" in endpoint or "history" in endpoint:
                    # GET è¯·æ±‚
                    response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                else:
                    # POST è¯·æ±‚ï¼ˆé¢„æœŸä¼šå¤±è´¥ä½†ç«¯ç‚¹åº”è¯¥å­˜åœ¨ï¼‰
                    response = requests.post(f"{self.base_url}{endpoint}",
                                          json={"test": True}, timeout=10)

                duration = time.time() - start_time

                # æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å­˜åœ¨ï¼ˆä¸æ˜¯404ï¼‰
                if response.status_code != 404:
                    self.log_test_result("api_endpoints", test_name, "PASS", {
                        "status_code": response.status_code,
                        "response_time": f"{duration:.3f}s"
                    }, duration)
                    print(f"   âœ… {endpoint_pattern}: çŠ¶æ€ç  {response.status_code}")
                else:
                    self.log_test_result("api_endpoints", test_name, "FAIL", {
                        "error": "ç«¯ç‚¹ä¸å­˜åœ¨",
                        "status_code": 404
                    }, duration)
                    print(f"   âŒ {endpoint_pattern}: ç«¯ç‚¹ä¸å­˜åœ¨")

            except Exception as e:
                duration = time.time() - start_time
                self.log_test_result("api_endpoints", test_name, "FAIL", {
                    "error": str(e)
                }, duration)
                print(f"   âŒ {endpoint_pattern}: {str(e)}")

    def test_data_flow_and_state_sync(self):
        """æµ‹è¯•æ•°æ®æµå’ŒçŠ¶æ€åŒæ­¥"""
        print("ğŸ”„ æµ‹è¯•2: æ•°æ®æµå’ŒçŠ¶æ€åŒæ­¥")

        # æµ‹è¯•çŠ¶æ€æŸ¥è¯¢çš„æ•°æ®å®Œæ•´æ€§
        test_name = "çŠ¶æ€æŸ¥è¯¢æ•°æ®å®Œæ•´æ€§"
        start_time = time.time()

        try:
            response = requests.get(f"{self.base_url}/api/v1/approval/status/{self.test_quote_id}",
                                  timeout=10)
            duration = time.time() - start_time

            if response.status_code == 200:
                data = response.json()

                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['quote_id', 'quote_number', 'approval_status',
                                 'approval_method', 'has_wecom_approval']

                missing_fields = [field for field in required_fields if field not in data]

                if not missing_fields:
                    # éªŒè¯æ•°æ®ç±»å‹å’Œé€»è¾‘
                    validation_issues = []

                    if not isinstance(data.get('has_wecom_approval'), bool):
                        validation_issues.append("has_wecom_approval åº”è¯¥æ˜¯å¸ƒå°”å€¼")

                    if data.get('approval_method') not in ['internal', 'wecom']:
                        validation_issues.append("approval_method å€¼æ— æ•ˆ")

                    # éªŒè¯é€»è¾‘ä¸€è‡´æ€§ï¼šä¼ä¸šå¾®ä¿¡IDä¸å®¡æ‰¹æ–¹å¼çš„å¯¹åº”å…³ç³»
                    has_wecom_id = bool(data.get('wecom_approval_id'))
                    is_wecom_method = data.get('approval_method') == 'wecom'

                    if has_wecom_id != is_wecom_method:
                        validation_issues.append("ä¼ä¸šå¾®ä¿¡IDä¸å®¡æ‰¹æ–¹å¼ä¸ä¸€è‡´")

                    if not validation_issues:
                        self.log_test_result("data_flow", test_name, "PASS", {
                            "data_fields": len(data),
                            "approval_method": data.get('approval_method'),
                            "has_wecom_approval": data.get('has_wecom_approval')
                        }, duration)
                        print(f"   âœ… çŠ¶æ€æŸ¥è¯¢æ•°æ®å®Œæ•´ä¸”ä¸€è‡´")
                    else:
                        self.log_test_result("data_flow", test_name, "WARN", {
                            "validation_issues": validation_issues,
                            "data": data
                        }, duration)
                        print(f"   âš ï¸ æ•°æ®éªŒè¯è­¦å‘Š: {', '.join(validation_issues)}")
                else:
                    self.log_test_result("data_flow", test_name, "FAIL", {
                        "missing_fields": missing_fields
                    }, duration)
                    print(f"   âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}")
            else:
                self.log_test_result("data_flow", test_name, "FAIL", {
                    "status_code": response.status_code,
                    "response": response.text[:200]
                }, duration)
                print(f"   âŒ çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {response.status_code}")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("data_flow", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {str(e)}")

    def test_approval_method_compatibility(self):
        """æµ‹è¯•ä¼ä¸šå¾®ä¿¡/å†…éƒ¨å®¡æ‰¹å…¼å®¹æ€§"""
        print("ğŸ¢ æµ‹è¯•3: å®¡æ‰¹æ–¹å¼å…¼å®¹æ€§")

        # æµ‹è¯•ä¸åŒå®¡æ‰¹æ–¹å¼çš„æ•°æ®è·å–
        test_name = "å®¡æ‰¹æ–¹å¼å…¼å®¹æ€§æ£€æŸ¥"
        start_time = time.time()

        try:
            # è·å–æ‰€æœ‰æŠ¥ä»·å•çš„å®¡æ‰¹æ–¹å¼åˆ†å¸ƒ
            query = text("""
                SELECT
                    approval_method,
                    COUNT(*) as count,
                    COUNT(CASE WHEN wecom_approval_id IS NOT NULL AND wecom_approval_id != '' THEN 1 END) as with_wecom_id
                FROM quotes
                WHERE is_deleted = 0
                GROUP BY approval_method
            """)

            result = self.db.execute(query)
            methods = result.fetchall()

            duration = time.time() - start_time

            method_stats = {}
            total_quotes = 0
            consistent_data = True

            for method, count, with_wecom_id in methods:
                method_stats[method] = {
                    "count": count,
                    "with_wecom_id": with_wecom_id
                }
                total_quotes += count

                # æ£€æŸ¥ä¸€è‡´æ€§ï¼šwecomæ–¹å¼åº”è¯¥éƒ½æœ‰wecom_idï¼Œinternalæ–¹å¼åº”è¯¥éƒ½æ²¡æœ‰
                if method == "wecom" and with_wecom_id != count:
                    consistent_data = False
                elif method == "internal" and with_wecom_id > 0:
                    consistent_data = False

            if consistent_data and total_quotes > 0:
                self.log_test_result("integration", test_name, "PASS", {
                    "total_quotes": total_quotes,
                    "method_distribution": method_stats,
                    "consistency": "perfect"
                }, duration)
                print(f"   âœ… å®¡æ‰¹æ–¹å¼å…¼å®¹æ€§è‰¯å¥½: {total_quotes} ä¸ªæŠ¥ä»·å•")
                print(f"      æ–¹å¼åˆ†å¸ƒ: {method_stats}")
            elif total_quotes == 0:
                self.log_test_result("integration", test_name, "WARN", {
                    "message": "æ²¡æœ‰æµ‹è¯•æ•°æ®"
                }, duration)
                print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®")
            else:
                self.log_test_result("integration", test_name, "FAIL", {
                    "consistency_issues": "æ•°æ®ä¸ä¸€è‡´",
                    "method_distribution": method_stats
                }, duration)
                print(f"   âŒ å®¡æ‰¹æ–¹å¼æ•°æ®ä¸ä¸€è‡´")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("integration", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")

    def test_frontend_integration(self):
        """æµ‹è¯•å‰ç«¯é›†æˆ"""
        print("ğŸŒ æµ‹è¯•4: å‰ç«¯é›†æˆ")

        # æµ‹è¯•å‰ç«¯å¯è®¿é—®æ€§
        test_name = "å‰ç«¯åº”ç”¨å¯è®¿é—®æ€§"
        start_time = time.time()

        try:
            response = requests.get(self.frontend_url, timeout=10)
            duration = time.time() - start_time

            if response.status_code == 200:
                content_length = len(response.text)
                has_react = "React" in response.text or "react" in response.text

                self.log_test_result("integration", test_name, "PASS", {
                    "status_code": response.status_code,
                    "content_length": content_length,
                    "has_react": has_react,
                    "response_time": f"{duration:.3f}s"
                }, duration)
                print(f"   âœ… å‰ç«¯åº”ç”¨æ­£å¸¸è®¿é—® ({content_length} å­—ç¬¦)")
            else:
                self.log_test_result("integration", test_name, "FAIL", {
                    "status_code": response.status_code
                }, duration)
                print(f"   âŒ å‰ç«¯åº”ç”¨è®¿é—®å¤±è´¥: {response.status_code}")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("integration", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ å‰ç«¯è®¿é—®å¼‚å¸¸: {str(e)}")

        # æ£€æŸ¥å…³é”®å‰ç«¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        test_name = "å‰ç«¯ç»Ÿä¸€å®¡æ‰¹ç»„ä»¶æ–‡ä»¶"
        start_time = time.time()

        try:
            frontend_files = [
                "frontend/chip-quotation-frontend/src/services/unifiedApprovalApi.js",
                "frontend/chip-quotation-frontend/src/components/UnifiedApprovalPanel.js",
                "frontend/chip-quotation-frontend/src/test_unified_approval_frontend.js"
            ]

            project_root = os.path.dirname(os.path.dirname(__file__))
            missing_files = []
            existing_files = []

            for file_path in frontend_files:
                full_path = os.path.join(project_root, file_path)
                if os.path.exists(full_path):
                    file_size = os.path.getsize(full_path)
                    existing_files.append({"path": file_path, "size": file_size})
                else:
                    missing_files.append(file_path)

            duration = time.time() - start_time

            if not missing_files:
                self.log_test_result("integration", test_name, "PASS", {
                    "total_files": len(frontend_files),
                    "existing_files": existing_files
                }, duration)
                print(f"   âœ… å‰ç«¯ç»„ä»¶æ–‡ä»¶å®Œæ•´: {len(existing_files)} ä¸ªæ–‡ä»¶")
            else:
                self.log_test_result("integration", test_name, "FAIL", {
                    "missing_files": missing_files,
                    "existing_files": existing_files
                }, duration)
                print(f"   âŒ ç¼ºå°‘å‰ç«¯æ–‡ä»¶: {len(missing_files)} ä¸ª")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("integration", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ å‰ç«¯æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {str(e)}")

    def test_performance_and_load(self):
        """æµ‹è¯•æ€§èƒ½å’Œè´Ÿè½½"""
        print("âš¡ æµ‹è¯•5: æ€§èƒ½å’Œè´Ÿè½½æµ‹è¯•")

        # APIå“åº”æ—¶é—´æµ‹è¯•
        test_name = "APIå“åº”æ—¶é—´æ€§èƒ½"
        print("   ğŸ”„ æ‰§è¡ŒAPIå“åº”æ—¶é—´æµ‹è¯•...")

        start_time = time.time()
        response_times = []
        successful_requests = 0

        try:
            # å¹¶å‘æµ‹è¯•APIå“åº”æ—¶é—´
            for i in range(10):
                req_start = time.time()
                try:
                    response = requests.get(f"{self.base_url}/api/v1/approval/status/{self.test_quote_id}",
                                          timeout=5)
                    req_duration = time.time() - req_start
                    if response.status_code == 200:
                        response_times.append(req_duration)
                        successful_requests += 1
                except:
                    pass

            duration = time.time() - start_time

            if response_times:
                avg_time = sum(response_times) / len(response_times)
                max_time = max(response_times)
                min_time = min(response_times)

                # æ€§èƒ½æ ‡å‡†ï¼šå¹³å‡å“åº”æ—¶é—´ < 1ç§’ï¼Œæœ€å¤§å“åº”æ—¶é—´ < 2ç§’
                performance_good = avg_time < 1.0 and max_time < 2.0

                status = "PASS" if performance_good else "WARN"
                self.log_test_result("performance", test_name, status, {
                    "total_requests": 10,
                    "successful_requests": successful_requests,
                    "avg_response_time": f"{avg_time:.3f}s",
                    "min_response_time": f"{min_time:.3f}s",
                    "max_response_time": f"{max_time:.3f}s",
                    "success_rate": f"{successful_requests/10*100:.1f}%"
                }, duration)

                if performance_good:
                    print(f"   âœ… APIæ€§èƒ½è‰¯å¥½: å¹³å‡ {avg_time:.3f}s, æˆåŠŸç‡ {successful_requests/10*100:.1f}%")
                else:
                    print(f"   âš ï¸ APIæ€§èƒ½éœ€ä¼˜åŒ–: å¹³å‡ {avg_time:.3f}s, æœ€å¤§ {max_time:.3f}s")
            else:
                self.log_test_result("performance", test_name, "FAIL", {
                    "error": "æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥"
                }, duration)
                print(f"   âŒ APIæ€§èƒ½æµ‹è¯•å¤±è´¥: æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("performance", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {str(e)}")

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶"""
        print("ğŸš¨ æµ‹è¯•6: é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶")

        # æµ‹è¯•æ— æ•ˆçš„quote_id
        test_name = "æ— æ•ˆquote_idå¤„ç†"
        start_time = time.time()

        try:
            invalid_id = "invalid-quote-id-123"
            response = requests.get(f"{self.base_url}/api/v1/approval/status/{invalid_id}",
                                  timeout=10)
            duration = time.time() - start_time

            # åº”è¯¥è¿”å›404æˆ–ç±»ä¼¼çš„é”™è¯¯çŠ¶æ€ç 
            if response.status_code in [404, 400, 422]:
                self.log_test_result("error_handling", test_name, "PASS", {
                    "status_code": response.status_code,
                    "error_handled": True
                }, duration)
                print(f"   âœ… æ— æ•ˆIDæ­£ç¡®å¤„ç†: çŠ¶æ€ç  {response.status_code}")
            else:
                self.log_test_result("error_handling", test_name, "WARN", {
                    "status_code": response.status_code,
                    "expected": "4xx error code"
                }, duration)
                print(f"   âš ï¸ æ— æ•ˆIDå¤„ç†å¼‚å¸¸: çŠ¶æ€ç  {response.status_code}")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("error_handling", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {str(e)}")

    def test_api_documentation(self):
        """æµ‹è¯•APIæ–‡æ¡£å®Œæ•´æ€§"""
        print("ğŸ“š æµ‹è¯•7: APIæ–‡æ¡£å®Œæ•´æ€§")

        test_name = "OpenAPIæ–‡æ¡£éªŒè¯"
        start_time = time.time()

        try:
            response = requests.get(f"{self.base_url}/openapi.json", timeout=10)
            duration = time.time() - start_time

            if response.status_code == 200:
                openapi_spec = response.json()

                # æ£€æŸ¥ç»Ÿä¸€å®¡æ‰¹ç«¯ç‚¹æ˜¯å¦åœ¨æ–‡æ¡£ä¸­
                paths = openapi_spec.get('paths', {})
                approval_endpoints = [path for path in paths.keys() if '/approval/' in path]

                # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾ä¿¡æ¯
                has_approval_tag = False
                tags = openapi_spec.get('tags', [])
                for tag in tags:
                    if 'approval' in tag.get('name', '').lower():
                        has_approval_tag = True
                        break

                if len(approval_endpoints) >= 5:  # åº”è¯¥æœ‰è‡³å°‘5ä¸ªç»Ÿä¸€å®¡æ‰¹ç«¯ç‚¹
                    self.log_test_result("documentation", test_name, "PASS", {
                        "total_approval_endpoints": len(approval_endpoints),
                        "has_approval_tag": has_approval_tag,
                        "endpoints": approval_endpoints
                    }, duration)
                    print(f"   âœ… APIæ–‡æ¡£å®Œæ•´: {len(approval_endpoints)} ä¸ªå®¡æ‰¹ç«¯ç‚¹")
                else:
                    self.log_test_result("documentation", test_name, "WARN", {
                        "total_approval_endpoints": len(approval_endpoints),
                        "expected_minimum": 5
                    }, duration)
                    print(f"   âš ï¸ APIæ–‡æ¡£ä¸å®Œæ•´: åªæœ‰ {len(approval_endpoints)} ä¸ªç«¯ç‚¹")
            else:
                self.log_test_result("documentation", test_name, "FAIL", {
                    "status_code": response.status_code
                }, duration)
                print(f"   âŒ OpenAPIæ–‡æ¡£è®¿é—®å¤±è´¥: {response.status_code}")

        except Exception as e:
            duration = time.time() - start_time
            self.log_test_result("documentation", test_name, "FAIL", {
                "error": str(e)
            }, duration)
            print(f"   âŒ æ–‡æ¡£éªŒè¯å¼‚å¸¸: {str(e)}")

    def generate_recommendations(self):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
        if self.test_results["failed_tests"] > 0:
            recommendations.append("å­˜åœ¨æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤ç›¸å…³é—®é¢˜")

        if self.test_results["warnings"] > 0:
            recommendations.append("å­˜åœ¨è­¦å‘Šé¡¹ï¼Œå»ºè®®ä¼˜åŒ–ç›¸å…³åŠŸèƒ½")

        # æ£€æŸ¥æ€§èƒ½æµ‹è¯•ç»“æœ
        perf_tests = self.test_results["test_categories"]["performance"]["tests"]
        for test in perf_tests:
            if test["status"] == "WARN":
                recommendations.append("APIå“åº”æ—¶é—´éœ€è¦ä¼˜åŒ–ï¼Œå»ºè®®è¿›è¡Œæ€§èƒ½è°ƒä¼˜")

        # æ£€æŸ¥é”™è¯¯å¤„ç†
        error_tests = self.test_results["test_categories"]["error_handling"]["tests"]
        if len(error_tests) == 0:
            recommendations.append("å»ºè®®å¢åŠ æ›´å¤šé”™è¯¯å¤„ç†æµ‹è¯•ç”¨ä¾‹")

        if not recommendations:
            recommendations.append("ç³»ç»Ÿæµ‹è¯•è¡¨ç°è‰¯å¥½ï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨")

        self.test_results["recommendations"] = recommendations

    def save_test_report(self, filename: Optional[str] = None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"unified_system_test_report_{timestamp}.json"

        filepath = os.path.join(os.path.dirname(__file__), filename)

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {filepath}")
            return filepath
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return None

    def print_summary_report(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“Š ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿæµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 80)

        total = self.test_results["total_tests"]
        passed = self.test_results["passed_tests"]
        failed = self.test_results["failed_tests"]
        warnings = self.test_results["warnings"]

        print(f"ğŸ” æµ‹è¯•ä¼šè¯: {self.test_results['test_session_id']}")
        print(f"â±ï¸ æµ‹è¯•æ—¶é•¿: {self.test_results['duration']}")
        print(f"ğŸ“Š æµ‹è¯•æ€»æ•°: {total}")
        print(f"âœ… é€šè¿‡: {passed} ({passed/total*100:.1f}%)" if total > 0 else "âœ… é€šè¿‡: 0")
        print(f"âŒ å¤±è´¥: {failed} ({failed/total*100:.1f}%)" if total > 0 else "âŒ å¤±è´¥: 0")
        print(f"âš ï¸ è­¦å‘Š: {warnings} ({warnings/total*100:.1f}%)" if total > 0 else "âš ï¸ è­¦å‘Š: 0")

        print("\nğŸ“‹ åˆ†ç±»æµ‹è¯•ç»“æœ:")
        for category, results in self.test_results["test_categories"].items():
            category_total = results["passed"] + results["failed"]
            if category_total > 0:
                pass_rate = results["passed"] / category_total * 100
                print(f"   {category}: {results['passed']}/{category_total} é€šè¿‡ ({pass_rate:.1f}%)")

        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(self.test_results["recommendations"], 1):
            print(f"   {i}. {rec}")

        # è¯„ä¼°æ•´ä½“è´¨é‡
        if total > 0:
            overall_score = (passed + warnings * 0.5) / total * 100
            print(f"\nğŸ¯ ç³»ç»Ÿè´¨é‡è¯„åˆ†: {overall_score:.1f}/100")

            if overall_score >= 90:
                print("ğŸ‰ ç³»ç»Ÿè´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ï¼")
            elif overall_score >= 75:
                print("âœ… ç³»ç»Ÿè´¨é‡è‰¯å¥½ï¼Œå»ºè®®ä¿®å¤è­¦å‘Šé¡¹åæŠ•å…¥ä½¿ç”¨")
            elif overall_score >= 60:
                print("âš ï¸ ç³»ç»Ÿè´¨é‡ä¸€èˆ¬ï¼Œéœ€è¦ä¿®å¤å¤±è´¥é¡¹å’Œè­¦å‘Šé¡¹")
            else:
                print("ğŸš¨ ç³»ç»Ÿè´¨é‡è¾ƒå·®ï¼Œéœ€è¦é‡å¤§æ”¹è¿›")

        print("=" * 80)

    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢çš„ç³»ç»Ÿæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿå…¨é¢æµ‹è¯•")
        print("=" * 80)
        print()

        start_time = time.time()

        try:
            # æ‰§è¡Œå„é¡¹æµ‹è¯•
            self.test_api_endpoints_completeness()
            print()

            self.test_data_flow_and_state_sync()
            print()

            self.test_approval_method_compatibility()
            print()

            self.test_frontend_integration()
            print()

            self.test_performance_and_load()
            print()

            self.test_error_handling()
            print()

            self.test_api_documentation()
            print()

            # è®¡ç®—æµ‹è¯•æ—¶é•¿
            end_time = time.time()
            duration = end_time - start_time
            self.test_results["end_time"] = datetime.now().isoformat()
            self.test_results["duration"] = f"{duration:.2f}s"

            # ç”Ÿæˆå»ºè®®
            self.generate_recommendations()

            # ä¿å­˜æŠ¥å‘Š
            report_file = self.save_test_report()

            # æ‰“å°æ€»ç»“
            self.print_summary_report()

            return True, report_file

        except Exception as e:
            print(f"âŒ ç³»ç»Ÿæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False, None

        finally:
            self.db.close()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ§ª Step 6: ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿå…¨é¢æµ‹è¯•")
    print("=" * 80)
    print()

    tester = UnifiedApprovalSystemTest()
    success, report_file = tester.run_comprehensive_test()

    if success:
        print("\nâœ… ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        if report_file:
            print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        return 0
    else:
        print("\nâŒ ç»Ÿä¸€å®¡æ‰¹ç³»ç»Ÿæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    exit(main())